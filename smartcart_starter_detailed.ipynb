{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a742351",
   "metadata": {},
   "source": [
    "# üõçÔ∏è SmartCart Starter Notebook\n",
    "This notebook will guide you through your group project on collaborative filtering and association rule mining for an e-commerce recommender system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20914f63",
   "metadata": {},
   "source": [
    "## üì• Part 1: Data Preprocessing\n",
    "Steps:\n",
    "- Load `ecommerce_user_data.csv` and `product_details.csv`\n",
    "- Merge data if necessary\n",
    "- Create user-item matrix\n",
    "- Fill missing ratings with 0\n",
    "- Group user behavior by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d42a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "user_data = pd.read_csv('data/ecommerce_user_data.csv')\n",
    "product_data = pd.read_csv('data/product_details.csv')\n",
    "\n",
    "print(user_data.head())\n",
    "print(product_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-item matrix\n",
    "user_item_matrix = user_data.pivot_table(index='UserID', columns='ProductID', values='Rating')\n",
    "user_item_matrix_filled = user_item_matrix.fillna(0)\n",
    "user_item_matrix_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c883fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate user behavior by category\n",
    "user_category_agg = user_data.groupby(['UserID', 'Category']).agg({'Rating': ['count', 'mean']}).reset_index()\n",
    "user_category_agg.columns = ['UserID', 'Category', 'TotalInteractions', 'AverageRating']\n",
    "user_category_agg.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ba0f385",
   "metadata": {},
   "source": [
    "## ü§ù Part 2: User-Based Collaborative Filtering\n",
    "Steps:\n",
    "- Use cosine similarity to compare users\n",
    "- Identify Top-N Similar Users\n",
    "- Generate Product Recommendations\n",
    "-  Generate Recommendations for All Users\n",
    "- Evaluation: Precision@5, Recall@5, and Coverage\n",
    "- Save Recommendations to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity between users\n",
    "user_similarity = cosine_similarity(user_item_matrix_filled)\n",
    "\n",
    "# Put into a DataFrame for easier reading\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix_filled.index, columns=user_item_matrix_filled.index)\n",
    "print(user_similarity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Top-N Similar Users for Each User\n",
    "def get_top_n_similar_users(user_id, n=5, threshold=0.1):\n",
    "    if user_id not in user_similarity_df:\n",
    "        return []\n",
    "    sorted_users = user_similarity_df[user_id].sort_values(ascending=False)\n",
    "    # Filter out weak similarities and the user themself\n",
    "    filtered = sorted_users[(sorted_users > threshold) & (sorted_users.index != user_id)]\n",
    "    return filtered.head(n).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend products for a given user based on similar users\n",
    "def recommend_products(user_id, n_similar=5, n_recommendations=5):\n",
    "    # Skip if user not found in matrix\n",
    "    if user_id not in user_item_matrix_filled.index:\n",
    "        return []\n",
    "    \n",
    "    # Get top N similar users with similarity threshold applied\n",
    "    top_users = get_top_n_similar_users(user_id, n_similar)\n",
    "    if not top_users:\n",
    "        return []\n",
    "    \n",
    "    # Identify which products the current user hasn't rated yet\n",
    "    user_ratings = user_item_matrix_filled.loc[user_id]\n",
    "    unseen_products = user_ratings[user_ratings == 0].index\n",
    "\n",
    "    # Get ratings from similar users for only unseen products\n",
    "    similar_users_ratings = user_item_matrix_filled.loc[top_users]\n",
    "    \n",
    "    # Only consider ratings that are 3 or higher (positive feedback)\n",
    "    positive_ratings = similar_users_ratings[unseen_products]\n",
    "    positive_ratings = positive_ratings.where(positive_ratings >= 3)\n",
    "\n",
    "    # Average the ratings from similar users and drop products with no ratings\n",
    "    avg_ratings = positive_ratings.mean(axis=0).dropna()\n",
    "    if avg_ratings.empty:\n",
    "        return []\n",
    "    \n",
    "     # Return top-N products with highest average rating\n",
    "    top_products = avg_ratings.sort_values(ascending=False).head(n_recommendations)\n",
    "    return top_products.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1439a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_details = pd.read_csv('product_details.csv')\n",
    "\n",
    "# Generate Recommendations for All Users\n",
    "recommendations = {}\n",
    "for user in user_item_matrix_filled.index:\n",
    "    recommendations[user] = recommend_products(user, n_similar=5, n_recommendations=5)\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommendations_df = pd.DataFrame.from_dict(recommendations, orient='index')\n",
    "recommendations_df.columns = [f\"Rec_{i+1}\" for i in range(recommendations_df.shape[1])]\n",
    "print(recommendations_df.head())\n",
    "\n",
    "# Create a mapping from ProductID to Category\n",
    "product_to_category = product_details.set_index('ProductID')['Category'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c05cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_data = pd.read_csv('ecommerce_user_data.csv')\n",
    "\n",
    "# Precision@K: How many of the recommended categories match the user‚Äôs actual preferred categories\n",
    "def precision_at_k(user_id, recommended_items, k=5):\n",
    "    actual_positive_categories = set(\n",
    "        ecommerce_data[\n",
    "            (ecommerce_data['UserID'] == user_id) & \n",
    "            (ecommerce_data['Rating'] >= 3)\n",
    "        ]['ProductID'].map(product_to_category)\n",
    "    )\n",
    "\n",
    "    recommended_categories = set(pd.Series(recommended_items[:k]).map(product_to_category))\n",
    "\n",
    "    if not actual_positive_categories:\n",
    "        return 0.0\n",
    "\n",
    "    return len(actual_positive_categories.intersection(recommended_categories)) / k\n",
    "\n",
    "# Recall@K: How many of the user's actual preferred categories are captured in the recommendations\n",
    "def recall_at_k(user_id, recommended_items, k=5):\n",
    "    actual_positive_categories = set(\n",
    "        ecommerce_data[\n",
    "            (ecommerce_data['UserID'] == user_id) & \n",
    "            (ecommerce_data['Rating'] >= 3)\n",
    "        ]['ProductID'].map(product_to_category)\n",
    "    )\n",
    "\n",
    "    recommended_categories = set(pd.Series(recommended_items[:k]).map(product_to_category))\n",
    "\n",
    "    if not actual_positive_categories:\n",
    "        return 0.0\n",
    "\n",
    "    return len(actual_positive_categories.intersection(recommended_categories)) / len(actual_positive_categories)\n",
    "\n",
    "# Collect precision and recall scores across all users\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Compute average precision and recall for the entire system\n",
    "for user in recommendations_df.index:\n",
    "    recommended = recommendations_df.loc[user].dropna().tolist()\n",
    "    precision_scores.append(precision_at_k(user, recommended))\n",
    "    recall_scores.append(recall_at_k(user, recommended))\n",
    "\n",
    "avg_precision = sum(precision_scores) / len(precision_scores)\n",
    "avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "print(f\"Average Precision@5: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall@5: {avg_recall:.2f}\")\n",
    "\n",
    "# Calculate coverage: % of users who received at least 1 recommendation\n",
    "users_with_recommendations = recommendations_df.apply(lambda row: row.notna().any(), axis=1).sum()\n",
    "total_users = len(recommendations_df)\n",
    "coverage = users_with_recommendations / total_users\n",
    "\n",
    "print(f\"Recommendation Coverage: {coverage:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to csv\n",
    "recommendations_df.to_csv(\"recommendations_output.csv\", index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebbeaa43",
   "metadata": {},
   "source": [
    "## üîç Part 3: Association Rule Mining (Apriori)\n",
    "Steps:\n",
    "- Convert user-product interactions to transaction format\n",
    "- Apply Apriori algorithm to find frequent itemsets\n",
    "- Generate association rules (support, confidence, lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to transaction format\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "transactions = user_data.groupby('UserID')['ProductID'].apply(list).tolist()\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_trans = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf18eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Apriori and generate rules\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "frequent_itemsets = apriori(df_trans, min_support=0.05, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
    "rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "651bef33",
   "metadata": {},
   "source": [
    "## üìä Part 4: Visualization\n",
    "Steps:\n",
    "- Plot user similarity heatmap\n",
    "- Plot top frequent itemsets\n",
    "- Visualize top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of user similarity\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_transactions = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df_transactions.corr(), cmap='YlGnBu')\n",
    "plt.title('User Similarity Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent itemsets bar chart\n",
    "frequent_itemsets.nlargest(10, 'support').plot(kind='bar', x='itemsets', y='support', legend=False)\n",
    "plt.title('Top 10 Frequent Itemsets')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89b8b9e4",
   "metadata": {},
   "source": [
    "## üß† Part 5: Conceptual Questions\n",
    "Answer the following questions in your report:\n",
    "1. How does data sparsity affect performance?\n",
    "2. What kinds of product bundles were discovered?\n",
    "3. What improvements would you suggest for real-world deployment?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
